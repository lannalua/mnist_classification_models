CNN v1: 
Time: 4.894196229733336 min 
Média treino accuracy: 0.9603111028671265
Média validação accuracy: 0.9881666660308838
Média treino loss:0.1306777834892273
Média validação loss: 0.04517147243022919
Acurácia no teste: 0.9878
Perda no teste: 0.0380

CNN v2: 
Time: 8.68619173765 min 
Média treino accuracy: 0.984489415373121
Média validação accuracy: 0.9863095283508301
Média treino loss:0.04978847157742296
Média validação loss: 0.05595071081604276
Acurácia no teste: 0.9912
Perda no teste: 0.0284

melhor:
CNN - Grid Search v1: 
Time: 153.52350683808334
{'batch_size': 128, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7ac0d2e48230>], 'epochs': 12, 'model__conv_filters': (32, 64), 'model__dense_units': (256,), 'model__dropout_rate': 0.3, 'model__kernel_size': (3, 3), 'model__optimizer': 'adam'}
Média treino accuracy: 0.9970277845859528
Média validação accuracy: 0.9974166601896286
Média treino loss: 0.009329107822850347
Média validação loss: 0.00843162799719721
Acurácia no teste: 0.9921
Perda no teste: 0.0311

 v1: param_grid = {

    "model__conv_filters": [(32,), (32, 64)],   
    "model__dense_units": [(128,), (256,)],

    "model__kernel_size": [(3, 3)],                 
    "model__dropout_rate": [0.3],                   
    "model__optimizer": ["adam"],                   
    "batch_size": [128],                             
    "epochs": [12],
    "callbacks": [[es]]
}

CNN - Grid Search v2:
Melhores parâmetros:
 {'batch_size': 128, 
 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7cf004cde510>],
'epochs': 5, 
'model__conv_filters': (32, 64), 
'model__dense_units': (128,), 
'model__dropout_rate': 0.3, 
'model__kernel_size': (3, 3), 
'model__optimizer': 'adam'}

CNN - Grid Search v3: 
Time: 161.67017588765
{'batch_size': 128, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7ac10aa4b680>], 'epochs': 5, 'model__conv_filters': (32, 64), 'model__dense_units': (128,), 'model__dropout_rate': 0.3, 'model__kernel_size': (3, 3), 'model__optimizer': 'adam'}
Média treino accuracy: 0.9925740838050843
Média validação accuracy: 0.990833330154419
Média treino loss: 0.022578958049416543
Média validação loss: 0.041219472885131836
Acurácia no teste: 0.9897
Perda no teste: 0.0299

v3: param_grid = {
    "model__conv_filters": [(32,), (32, 64)],
    "model__dense_units": [(128,), (256,)],

    "model__kernel_size": [(3, 3)],
    "model__dropout_rate": [0.2, 0.3, 0.4],
    "model__optimizer": ["adam"],
    "batch_size": [128],
    "epochs": [5],
    "callbacks": [[es]]
}

CNN - Grid Search v4: 
Time: 224.3550534399333
{'batch_size': 128, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7ac0d3b48ad0>], 'epochs': 7, 'model__conv_filters': (32, 64), 'model__dense_units': (128,), 'model__dropout_rate': 0.3, 'model__kernel_size': (3, 3), 'model__optimizer': 'adam'}
Média treino accuracy: 0.9923444390296936
Média validação accuracy: 0.9910333395004273
Média treino loss: 0.023811094276607037
Média validação loss: 0.03657391667366028
Acurácia no teste: 0.9881
Perda no teste: 0.0376

v4: param_grid = {
    "model__conv_filters": [(32,), (32, 64)],
    "model__dense_units": [(128,), (256,)],

    "model__kernel_size": [(3, 3)],
    "model__dropout_rate": [0.2, 0.3, 0.4],
    "model__optimizer": ["adam"],
    "batch_size": [128],
    "epochs": [7],
    "callbacks": [[es]]
}

CNN - Grid Search v5: 
Add  "model__dropout_rate": [0.3, 0.3462, 0.3705],
Time: 174.47965763965001
{'batch_size': 128, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7c50e0681a00>], 'epochs': 7, 'model__conv_filters': (32, 64), 'model__dense_units': (256,), 'model__dropout_rate': 0.3462, 'model__kernel_size': (3, 3), 'model__optimizer': 'adam'}
Média treino accuracy: 0.993004634976387
Média validação accuracy: 0.9908333420753479
Média treino loss: 0.02114291931502521
Média validação loss: 0.037517085671424866
Acurácia no teste: 0.9920
Perda no teste: 0.0269

CNN - Random Search v1: 
Time: 196.05270757706663
{'batch_size': 32, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x79ed6c6ee4b0>], 'epochs': 10, 'model__conv_filters': (32, 64), 'model__dense_units': (128,), 'model__dropout_rate': np.float64(0.4240196152098194), 'model__kernel_size': (3, 3), 'model__optimizer': 'adam'}
Média treino accuracy: 0.9921234548091888
Média validação accuracy: 0.9917222162087759
Média treino loss: 0.02564048394560814
Média validação loss: 0.03827523828173677
Acurácia no teste: 0.9901
Perda no teste: 0.0326

param_distributions = {
    "model__conv_filters": [(32,), (32, 64)],
    "model__dense_units": [(128,), (256,)],

    "model__kernel_size": [(3, 3)],
    "model__dropout_rate": uniform(0.2, 0.4),
    'batch_size': [32, 64, 128],
    'model__optimizer': ['adam', 'rmsprop','sgd'],
    "epochs": [10],
    "callbacks": [[es]]
}

CNN - Random Search v2: 
Time: 255.53485829338334
Add: 16 no batch size e tirei 128. Dropout(0.3,0.4)
{'batch_size': 16, 'callbacks': [<keras.src.callbacks.early_stopping.EarlyStopping object at 0x7a685da64380>], 'epochs': 10, 'model__conv_filters': (32, 64), 'model__dense_units': (256,), 'model__dropout_rate': np.float64(0.4647564707009924), 'model__kernel_size': (3, 3), 'model__optimizer': 'sgd'}
Média treino accuracy: 0.991486770766122
Média validação accuracy: 0.9918571369988578
Média treino loss: 0.02572291557277952
Média validação loss: 0.03151575289666653
Acurácia no teste: 0.9909
Perda no teste: 0.0251
param_distributions = {
    "model__conv_filters": [(32,), (32, 64)],
    "model__dense_units": [(128,), (256,)],

    "model__kernel_size": [(3, 3)],
    "model__dropout_rate": uniform(0.3, 0.4),
    'batch_size': [16, 32, 64],
    'model__optimizer': ['adam', 'rmsprop','sgd'],
    "epochs": [10],
    "callbacks": [[es]]}

CNN - Bayesiana v1: 
Time: 191.56429765781667 min 
Melhor score: 0.9901
OrderedDict({'batch_size': 128, 'epochs': 10, 'model__conv_filters_str': '32_64', 'model__dense_units_str': '256', 'model__dropout_rate': 0.38077041450133736, 'model__kernel_size_str': '3_3', 'model__optimizer': 'rmsprop'})
Média treino accuracy: 0.9961805641651154
Média validação accuracy: 0.9926666468381882
Média treino loss: 0.012421314604580402
Média validação loss: 0.045392549596726894
Acurácia no teste: 0.9912
Perda no teste: 0.0389

CNN - Bayesiana v2: 
Time: 80.95489997163334 min 
Opção para a questão do erro de tupla 
Melhor score: 0.9878
OrderedDict({'batch_size': 128, 'epochs': 5, 'model__conv_filters1': 32, 'model__conv_filters2': 64, 'model__dense_units': 128, 'model__dropout_rate': 0.3190910078429987, 'model__optimizer': 'adam'})
Média treino accuracy: 0.9941296339035034
Média validação accuracy: 0.9915666580200195
Média treino loss: 0.01741894129663706
Média validação loss: 0.03390992805361748
Acurácia no teste: 0.9911
Perda no teste: 0.0303


CNN - Hyperband v1: 
Time: 126.27474719773335 min 
Trial 10 Complete [00h 11m 27s] 
 val_accuracy: 0.9912499785423279 
Best val_accuracy So Far: 0.991249978542327
Total elapsed time: 01h 03m 50s 
Melhores hiperparâmetros encontrados:
conv_blocks: 2 
filters_0: 32 
kernel_size: 3 
batch_norm_0: False 
dense_units: 128 
dropout: 0.4 
learning_rate: 0.001 
filters_1: 128 
batch_norm_1: False 
tuner/epochs: 6 
tuner/initial_epoch: 0 
tuner/bracket: 0 
tuner/round: 0 

Média treino accuracy: 0.9847129649586148
Média validação accuracy: 0.9887499941719903
Média treino loss: 0.0504416697141197
Média validação loss: 0.040389141274823084
Acurácia no teste: 0.9933
Perda no teste: 0.0218

CNN - Golden Section Search v1:
--- Início GSS | Otimizando Taxa de Dropout ---
Iteração 1: Intervalo [0.2528, 0.5000] | Testando 0.3472 e 0.4056 | Melhor Acurácia: 0.9933
Iteração 2: Intervalo [0.2528, 0.4056] | Testando 0.3111 e 0.3472 | Melhor Acurácia: 0.9933
Iteração 3: Intervalo [0.3111, 0.4056] | Testando 0.3472 e 0.3695 | Melhor Acurácia: 0.9933
Iteração 4: Intervalo [0.3111, 0.3695] | Testando 0.3334 e 0.3472 | Melhor Acurácia: 0.9933
Iteração 5: Intervalo [0.3334, 0.3695] | Testando 0.3472 e 0.3557 | Melhor Acurácia: 0.9933
Iteração 6: Intervalo [0.3334, 0.3557] | Testando 0.3420 e 0.3472 | Melhor Acurácia: 0.9933
Iteração 7: Intervalo [0.3420, 0.3557] | Testando 0.3472 e 0.3505 | Melhor Acurácia: 0.9933
Iteração 8: Intervalo [0.3420, 0.3505] | Testando 0.3452 e 0.3472 | Melhor Acurácia: 0.9933

--- Resultado Final ---
✅ Taxa de Dropout Ótima Encontrada: 0.3462
Tempo total gasto no GSS: 68.91 minutos

Modelo com o dropout 0.3462
Time: 4.988455988416664 min
Média treino accuracy: 0.984539344906807
Média validação accuracy: 0.9827291518449783
Média treino loss: 0.04963571089319885
Média validação loss: 0.06523849489167333
Acurácia no teste: 0.9907
Perda no teste: 0.0309

CNN - Golden Section Search v2:
--- Início GSS | Otimizando Taxa de Dropout ---
Iteração 1: Intervalo [0.2528, 0.5000] | Testando 0.3472 e 0.4056 | Melhor Acurácia: 0.9920
Iteração 2: Intervalo [0.2528, 0.4056] | Testando 0.3111 e 0.3472 | Melhor Acurácia: 0.9920
Iteração 3: Intervalo [0.3111, 0.4056] | Testando 0.3472 e 0.3695 | Melhor Acurácia: 0.9928
Iteração 4: Intervalo [0.3472, 0.4056] | Testando 0.3695 e 0.3833 | Melhor Acurácia: 0.9928
Iteração 5: Intervalo [0.3472, 0.3833] | Testando 0.3610 e 0.3695 | Melhor Acurácia: 0.9928
Iteração 6: Intervalo [0.3610, 0.3833] | Testando 0.3695 e 0.3748 | Melhor Acurácia: 0.9928
Iteração 7: Intervalo [0.3610, 0.3748] | Testando 0.3663 e 0.3695 | Melhor Acurácia: 0.9928
Iteração 8: Intervalo [0.3663, 0.3748] | Testando 0.3695 e 0.3715 | Melhor Acurácia: 0.9928

--- Resultado Final ---
✅ Taxa de Dropout Ótima Encontrada: 0.3705
Tempo total gasto no GSS: 47.59 minutos

Modelo com o dropout 0.3705
Time: 8.029721872883334 min
Média treino accuracy: 0.9809351861476898
Média validação accuracy: 0.9788055618604025
Média treino loss: 0.06115337926894426
Média validação loss: 0.07846438698470592
Acurácia no teste: 0.9891
Perda no teste: 0.0350

CNN - Golden Section Search v3: learning_rate, dropout, batch_size

--- [1/3] Buscando LR (Fixos: BS=64, Drop=0.0) ---
--- Início GSS | Otimizando Taxa de Dropout ---
Iteração 1: Intervalo [-4.0000, -2.1459] | Testando -3.2918 e -2.8541 | Melhor Acurácia: 0.9908
Iteração 2: Intervalo [-3.2918, -2.1459] | Testando -2.8541 e -2.5836 | Melhor Acurácia: 0.9908
Iteração 3: Intervalo [-3.2918, -2.5836] | Testando -3.0213 e -2.8541 | Melhor Acurácia: 0.9908
Iteração 4: Intervalo [-3.0213, -2.5836] | Testando -2.8541 e -2.7508 | Melhor Acurácia: 0.9922
Iteração 5: Intervalo [-2.8541, -2.5836] | Testando -2.7508 e -2.6869 | Melhor Acurácia: 0.9922
Iteração 6: Intervalo [-2.8541, -2.6869] | Testando -2.7902 e -2.7508 | Melhor Acurácia: 0.9922
>>> Vencedor LR: 0.00170

--- [2/3] Buscando Dropout (Fixos: LR=0.00170, BS=64) ---
 Dropout Testado: 0.2910 -> Accuracy: 0.9908
 Dropout Testado: 0.4090 -> Accuracy: 0.9897
--- Início GSS | Otimizando Taxa de Dropout ---
 Dropout Testado: 0.2180 -> Accuracy: 0.9872
Iteração 1: Intervalo [0.1000, 0.4090] | Testando 0.2180 e 0.2910 | Melhor Acurácia: 0.9908
 Dropout Testado: 0.3361 -> Accuracy: 0.9893
Iteração 2: Intervalo [0.2180, 0.4090] | Testando 0.2910 e 0.3361 | Melhor Acurácia: 0.9908
 Dropout Testado: 0.2631 -> Accuracy: 0.9910
Iteração 3: Intervalo [0.2180, 0.3361] | Testando 0.2631 e 0.2910 | Melhor Acurácia: 0.9910
 Dropout Testado: 0.2459 -> Accuracy: 0.9893
Iteração 4: Intervalo [0.2180, 0.2910] | Testando 0.2459 e 0.2631 | Melhor Acurácia: 0.9910
 Dropout Testado: 0.2738 -> Accuracy: 0.9897
Iteração 5: Intervalo [0.2459, 0.2910] | Testando 0.2631 e 0.2738 | Melhor Acurácia: 0.9910
 Dropout Testado: 0.2565 -> Accuracy: 0.9895
Iteração 6: Intervalo [0.2459, 0.2738] | Testando 0.2565 e 0.2631 | Melhor Acurácia: 0.9910
 Dropout Testado: 0.2672 -> Accuracy: 0.9912
Iteração 7: Intervalo [0.2565, 0.2738] | Testando 0.2631 e 0.2672 | Melhor Acurácia: 0.9912
 Dropout Testado: 0.2697 -> Accuracy: 0.9903
Iteração 8: Intervalo [0.2631, 0.2738] | Testando 0.2672 e 0.2697 | Melhor Acurácia: 0.9912
 Dropout Testado: 0.2656 -> Accuracy: 0.9865
Iteração 9: Intervalo [0.2631, 0.2697] | Testando 0.2656 e 0.2672 | Melhor Acurácia: 0.9912
>>> Vencedor Dropout: 0.2664


--- [3/3] Buscando Batch Size (Fixos: LR=0.00170, Drop=0.2664) ---
   Batch Testado: 58 -> Accuracy: 0.9913
   Batch Testado: 85 -> Accuracy: 0.9902
--- Início GSS | Otimizando Taxa de Dropout ---
   Batch Testado: 42 -> Accuracy: 0.9892
Iteração 1: Intervalo [16.0000, 85.2198] | Testando 42.4396 e 58.7802 | Melhor Acurácia: 0.9913
   Batch Testado: 68 -> Accuracy: 0.9910
Iteração 2: Intervalo [42.4396, 85.2198] | Testando 58.7802 e 68.8792 | Melhor Acurácia: 0.9913
   Batch Testado: 52 -> Accuracy: 0.9892
Iteração 3: Intervalo [42.4396, 68.8792] | Testando 52.5386 e 58.7802 | Melhor Acurácia: 0.9913
   Batch Testado: 62 -> Accuracy: 0.9897
Iteração 4: Intervalo [52.5386, 68.8792] | Testando 58.7802 e 62.6377 | Melhor Acurácia: 0.9913
   Batch Testado: 56 -> Accuracy: 0.9895
Iteração 5: Intervalo [52.5386, 62.6377] | Testando 56.3961 e 58.7802 | Melhor Acurácia: 0.9913
   Batch Testado: 60 -> Accuracy: 0.9892
Iteração 6: Intervalo [56.3961, 62.6377] | Testando 58.7802 e 60.2536 | Melhor Acurácia: 0.9913
>>> Vencedor Batch Size: 59
time: 51min

Tempo Total da Busca: 127.8 minutos + 51 minutos

Modelo treinado como os resultados
Média treino accuracy: 0.9864485594961379
Média validação accuracy: 0.9877962999873691
Média treino loss: 0.04558230108684964
Média validação loss: 0.04805627382463879
Acurácia no teste: 0.9898
Perda no teste: 0.0388
Tempo total gasto no modelo final: 10.88 minutos

CNN - Golden Section Search v4
--- [1/3] Buscando LR (Fixos: BS=64, Drop=0.0) ---
--- Início GSS | Otimizando Taxa de Dropout ---
Iteração 1: Intervalo [-4.0000, -2.1459] | Testando -3.2918 e -2.8541 | Melhor Acurácia: 0.9897
Iteração 2: Intervalo [-3.2918, -2.1459] | Testando -2.8541 e -2.5836 | Melhor Acurácia: 0.9897
Iteração 3: Intervalo [-3.2918, -2.5836] | Testando -3.0213 e -2.8541 | Melhor Acurácia: 0.9897
Iteração 4: Intervalo [-3.0213, -2.5836] | Testando -2.8541 e -2.7508 | Melhor Acurácia: 0.9898
Iteração 5: Intervalo [-2.8541, -2.5836] | Testando -2.7508 e -2.6869 | Melhor Acurácia: 0.9898
Iteração 6: Intervalo [-2.7508, -2.5836] | Testando -2.6869 e -2.6475 | Melhor Acurácia: 0.9898
>>> Vencedor LR: 0.00215

--- [2/3] Buscando Dropout (Fixos: LR=0.00215, BS=64) ---
 Dropout Testado: 0.2910 -> Accuracy: 0.9885
 Dropout Testado: 0.4090 -> Accuracy: 0.9903
--- Início GSS | Otimizando Taxa de Dropout ---
 Dropout Testado: 0.4820 -> Accuracy: 0.9902
Iteração 1: Intervalo [0.2910, 0.6000] | Testando 0.4090 e 0.4820 | Melhor Acurácia: 0.9903
 Dropout Testado: 0.3639 -> Accuracy: 0.9915
Iteração 2: Intervalo [0.2910, 0.4820] | Testando 0.3639 e 0.4090 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3361 -> Accuracy: 0.9892
Iteração 3: Intervalo [0.2910, 0.4090] | Testando 0.3361 e 0.3639 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3812 -> Accuracy: 0.9910
Iteração 4: Intervalo [0.3361, 0.4090] | Testando 0.3639 e 0.3812 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3533 -> Accuracy: 0.9897
Iteração 5: Intervalo [0.3361, 0.3812] | Testando 0.3533 e 0.3639 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3705 -> Accuracy: 0.9908
Iteração 6: Intervalo [0.3533, 0.3812] | Testando 0.3639 e 0.3705 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3599 -> Accuracy: 0.9907
Iteração 7: Intervalo [0.3533, 0.3705] | Testando 0.3599 e 0.3639 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3664 -> Accuracy: 0.9893
Iteração 8: Intervalo [0.3599, 0.3705] | Testando 0.3639 e 0.3664 | Melhor Acurácia: 0.9915
 Dropout Testado: 0.3624 -> Accuracy: 0.9890
Iteração 9: Intervalo [0.3599, 0.3664] | Testando 0.3624 e 0.3639 | Melhor Acurácia: 0.9915
>>> Vencedor Dropout: 0.3632

--- [3/3] Buscando Batch Size (Fixos: LR=0.00215, Drop=0.3632) ---
   Batch Testado: 58 -> Accuracy: 0.9903
   Batch Testado: 85 -> Accuracy: 0.9890
--- Início GSS | Otimizando Taxa de Dropout ---
   Batch Testado: 42 -> Accuracy: 0.9913
Iteração 1: Intervalo [16.0000, 85.2198] | Testando 42.4396 e 58.7802 | Melhor Acurácia: 0.9913
   Batch Testado: 32 -> Accuracy: 0.9905
Iteração 2: Intervalo [16.0000, 58.7802] | Testando 32.3406 e 42.4396 | Melhor Acurácia: 0.9913
   Batch Testado: 48 -> Accuracy: 0.9900
Iteração 3: Intervalo [32.3406, 58.7802] | Testando 42.4396 e 48.6812 | Melhor Acurácia: 0.9913
   Batch Testado: 38 -> Accuracy: 0.9908
Iteração 4: Intervalo [32.3406, 48.6812] | Testando 38.5821 e 42.4396 | Melhor Acurácia: 0.9913
   Batch Testado: 44 -> Accuracy: 0.9892
Iteração 5: Intervalo [38.5821, 48.6812] | Testando 42.4396 e 44.8237 | Melhor Acurácia: 0.9913
   Batch Testado: 40 -> Accuracy: 0.9897
Iteração 6: Intervalo [38.5821, 44.8237] | Testando 40.9662 e 42.4396 | Melhor Acurácia: 0.9913
>>> Vencedor Batch Size: 41

Tempo Total do Learning Rate: 55.1 minutos

Tempo Total do Dropout: 73.8 minutos

Tempo Total do Batch_size: 55.6 minutos

Tempo Total da Busca: 184.5 minutos

Modelo treinado com os resultados
Config: LR=0.002151868508869105 | Drop=0.36315561749642483 | Batch=41

Média treino accuracy: 0.9794370532035828
Média validação accuracy: 0.9866999983787537
Média treino loss: 0.0711595058441162
Média validação loss: 0.0536638393998146
Acurácia no teste: 0.9868
Perda no teste: 0.0448

Tempo total gasto no modelo final: 5.84 minutos
Modelo Final Treinado!